import gradio as gr
import subprocess
import os
import uuid
import requests
import json
from datetime import datetime

OUTPUT_DIR = "output"
UPLOAD_DIR = "uploads"
CONFIG_FILE = "user_config.json"
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(UPLOAD_DIR, exist_ok=True)

MODEL_PRESETS = {
    "OpenAI": {
        "base_url": "https://api.openai.com/v1",
        "api_key": "",
        "default_model": "gpt-4o"
    },
    "DeepSeek": {
        "base_url": "https://api.deepseek.com/v1",
        "api_key": "",
        "default_model": "deepseek-chat"
    },
    "OpenAI Compatible": {
        "base_url": "https://api.gitcode.com/api/v5",
        "api_key": "",
        "default_model": "deepseek-ai/DeepSeek-V3.2-Exp"
    },
    "Ollama (æœ¬åœ°æ¨¡å‹)": {
        "base_url": "http://localhost:11434/v1",
        "api_key": "a",
        "default_model": "llama3"
    }
}

def load_user_config():
    """åŠ è½½ç”¨æˆ·é…ç½®"""
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
    return {}

def save_user_config(config):
    """ä¿å­˜ç”¨æˆ·é…ç½®"""
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return "é…ç½®å·²ä¿å­˜ âœ…"
    except Exception as e:
        return f"ä¿å­˜é…ç½®å¤±è´¥: {e}"

def save_current_settings(provider, api_key, base_url, model_name, lang_in, lang_out, 
                         dual_output, no_watermark, skip_clean, rich_text_disable, 
                         enhance, max_pages, min_length):
    """ä¿å­˜å½“å‰è®¾ç½®"""
    config = {
        "provider": provider,
        "api_key": api_key,
        "base_url": base_url,
        "model_name": model_name,
        "lang_in": lang_in,
        "lang_out": lang_out,
        "dual_output": dual_output,
        "no_watermark": no_watermark,
        "skip_clean": skip_clean,
        "rich_text_disable": rich_text_disable,
        "enhance": enhance,
        "max_pages": max_pages,
        "min_length": min_length
    }
    return save_user_config(config)

def run_babeldoc_translation(input_path, output_path, model_name, base_url, api_key, lang_in, lang_out,
                             dual_output, no_watermark, skip_clean, rich_text_disable,
                             enhance, max_pages, min_length):
    # Check for None values and provide defaults
    if not model_name:
        model_name = "gpt-4o"  # Default model
    if not base_url:
        base_url = "https://api.openai.com/v1"
    if not api_key:
        api_key = ""
    
    command = [
        "babeldoc",
        "--files", input_path,
        "--openai",
        "--openai-model", model_name,
        "--openai-base-url", base_url,
        "--openai-api-key", api_key,
        "--lang-in", lang_in,
        "--lang-out", lang_out,
        "--output", output_path
    ]

    if not dual_output:
        command.append("--no-dual")
    if no_watermark:
        command.extend(["--watermark-output-mode", "no_watermark"])
    if skip_clean:
        command.append("--skip-clean")
    if rich_text_disable:
        command.append("--disable-rich-text-translate")
    if enhance:
        command.append("--enhance-compatibility")
    if max_pages:
        command.extend(["--max-pages-per-part", str(max_pages)])
    if min_length:
        command.extend(["--min-text-length", str(min_length)])

    print("ğŸ“¦ æ‰§è¡Œå‘½ä»¤ï¼š", " ".join(command))

    try:
        subprocess.run(command, check=True)
    except subprocess.CalledProcessError as e:
        return f"ç¿»è¯‘å‡ºé”™ï¼š{str(e)}", None

    pdf_files = sorted(
        [f for f in os.listdir(output_path) if f.endswith(".pdf")],
        key=lambda x: os.path.getmtime(os.path.join(output_path, x)),
        reverse=True
    )
    if not pdf_files:
        return "ç¿»è¯‘å¤±è´¥ï¼šæœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶", None

    translated_path = os.path.join(output_path, pdf_files[0])
    return "ç¿»è¯‘å®Œæˆ âœ…ï¼Œç‚¹å‡»ä¸‹æ–¹é“¾æ¥ä¸‹è½½ï¼š", translated_path

def get_ollama_models():
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            tags = response.json().get("models", [])
            return [tag["name"] for tag in tags]
    except Exception:
        pass
    return ["llama3"]

def get_openai_models(api_key, base_url):
    try:
        headers = {"Authorization": f"Bearer {api_key}"}
        response = requests.get(f"{base_url}/models", headers=headers, timeout=5)
        if response.status_code == 200:
            models = response.json().get("data", [])
            return [m["id"] for m in models]
    except Exception:
        pass
    return []



def translate_pdf(pdf_file, provider, api_key, base_url, model_name,
                  lang_in, lang_out, dual_output, no_watermark,
                  skip_clean, rich_text_disable, enhance, max_pages, min_length):
    if not pdf_file:
        return "è¯·ä¸Šä¼  PDF æ–‡ä»¶", None
    
    # Validate required parameters
    if not model_name:
        return "è¯·é€‰æ‹©æ¨¡å‹åç§°", None
    if provider != "Ollama (æœ¬åœ°æ¨¡å‹)" and not api_key:
        return "è¯·è¾“å…¥ API Key", None
    if provider == "OpenAI Compatible" and not base_url:
        return "è¯·è¾“å…¥ API Base URL", None

    upload_pdfs = sorted(
        [f for f in os.listdir(UPLOAD_DIR) if f.endswith(".pdf")],
        key=lambda x: os.path.getmtime(os.path.join(UPLOAD_DIR, x)),
        reverse=True
    )
    for old_file in upload_pdfs[30:]:
        try:
            os.remove(os.path.join(UPLOAD_DIR, old_file))
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åˆ é™¤æ—§ä¸Šä¼ æ–‡ä»¶ï¼š{old_file}ï¼ŒåŸå› ï¼š{e}")

    file_id = str(uuid.uuid4())
    filename = os.path.basename(pdf_file)
    name_root = os.path.splitext(filename)[0]
    input_path = os.path.join(UPLOAD_DIR, f"{file_id}_{filename}")
    with open(pdf_file, "rb") as src, open(input_path, "wb") as dst:
        dst.write(src.read())

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_subdir = os.path.join(OUTPUT_DIR, f"{name_root}_{timestamp}")
    os.makedirs(output_subdir, exist_ok=True)

    print("âš™ï¸ å®é™…è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼š", input_path)
    return run_babeldoc_translation(
        input_path, output_subdir, model_name, base_url, api_key,
        lang_in, lang_out, dual_output, no_watermark,
        skip_clean, rich_text_disable, enhance, max_pages, min_length
    )

def update_provider(provider):
    preset = MODEL_PRESETS[provider]
    default_model = preset["default_model"]
    if provider == "Ollama (æœ¬åœ°æ¨¡å‹)":
        models = get_ollama_models()
        default = models[0] if models else "llama3"
        return preset["api_key"], preset["base_url"], default
    else:
        return preset["api_key"], preset["base_url"], default_model



def load_saved_settings():
    """åŠ è½½ä¿å­˜çš„è®¾ç½®"""
    config = load_user_config()
    if not config:
        return ("OpenAI", "", "https://api.openai.com/v1", "gpt-4o", "en", "zh", 
                True, True, True, True, True, "1", "5")
    
    return (
        config.get("provider", "OpenAI"),
        config.get("api_key", ""),
        config.get("base_url", "https://api.openai.com/v1"),
        config.get("model_name", "gpt-4o"),
        config.get("lang_in", "en"),
        config.get("lang_out", "zh"),
        config.get("dual_output", True),
        config.get("no_watermark", True),
        config.get("skip_clean", True),
        config.get("rich_text_disable", True),
        config.get("enhance", True),
        config.get("max_pages", "1"),
        config.get("min_length", "5")
    )

def refresh_models(api_key, base_url):
    models = get_openai_models(api_key, base_url)
    if not models:
        return "è·å–å¤±è´¥ âŒ"
    return models[0] if models else ""

# åœ¨åˆ›å»ºç•Œé¢å‰åŠ è½½ä¿å­˜çš„è®¾ç½®
saved_settings = load_saved_settings()

with gr.Blocks() as demo:
    gr.Markdown("# ğŸ“„ BabelDOC - å¤šæ¨¡å‹ PDF ç¿»è¯‘å·¥å…·")

    gr.Markdown(
        '''
## ğŸ“˜ å°æœæé†’æ‚¨ï¼ˆREADMEï¼‰

1. ä¸Šä¼ ä½ æƒ³ç¿»è¯‘çš„ PDF æ–‡ä»¶ï¼ˆç›®å‰ä»…æ”¯æŒ `.pdf`ï¼‰ã€‚
2. é€‰æ‹©ä½ è¦ä½¿ç”¨çš„æ¨¡å‹ï¼š
   - **OpenAI**: å®˜æ–¹ OpenAI API
   - **DeepSeek**: DeepSeek API
   - **OpenAI Compatible**: å…¼å®¹ OpenAI API çš„æœåŠ¡ï¼ˆå¦‚ GitCodeã€é€šä¹‰åƒé—®ç­‰ï¼‰
   - **Ollama**: æœ¬åœ°æ¨¡å‹
3. è¾“å…¥å¯¹åº”çš„ API Key å’Œ Base URLï¼ˆOpenAI Compatible éœ€è¦è‡ªå®šä¹‰ï¼‰ã€‚
4. é€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ï¼ˆå¦‚è‹±æ–‡ â†’ ä¸­æ–‡ï¼‰ã€‚
5. ğŸ’¾ **ä¿å­˜è®¾ç½®**: ç‚¹å‡»"ä¿å­˜å½“å‰è®¾ç½®"å¯ä¿å­˜é…ç½®ï¼Œä¸‹æ¬¡æ‰“å¼€è‡ªåŠ¨åŠ è½½ã€‚
6. æ ¹æ®éœ€è¦å‹¾é€‰é€‰é¡¹ï¼š
   - âœ… è¾“å‡ºåŒè¯­ï¼šåŸæ–‡+è¯‘æ–‡å¹¶æ’æ˜¾ç¤ºã€‚
   - âœ… æ— æ°´å°ï¼šå»é™¤â€œç”± BabelDOC ç”Ÿæˆâ€æ ‡è¯†ã€‚
   - âœ… è·³è¿‡æ¸…æ´—ï¼šä¿ç•™åŸå§‹æ’ç‰ˆï¼Œä¸å¯¹ PDF æ ¼å¼åšæ¸…ç†ã€‚
   - âœ… ç¦ç”¨å¯Œæ–‡æœ¬ï¼šé¿å…ä¿ç•™åŠ ç²—ã€è¶…é“¾æ¥ç­‰æ ¼å¼ã€‚
7. ç‚¹å‡» ğŸš€ å¼€å§‹ç¿»è¯‘ï¼Œç¨ç­‰ç‰‡åˆ»åå³å¯ä¸‹è½½ç¿»è¯‘ç»“æœã€‚
8. ç¿»è¯‘æ–‡ä»¶å°†è‡ªåŠ¨ä¿å­˜åœ¨ `output/åŸæ–‡ä»¶å_æ—¶é—´æˆ³/` ç›®å½•ä¸‹ã€‚

ğŸ“¢ æ¬¢è¿å…³æ³¨å°æœçš„Xï¼š
https://x.com/xiaodus

ğŸ“‚ **OpenAI Compatible ç¤ºä¾‹**:
- GitCode: Base URL å¡«å†™ `https://api.gitcode.com/api/v5` (ä¸è¦åŒ…å« /chat/completions)
- é€šä¹‰åƒé—®: Base URL å¡«å†™ `https://dashscope.aliyuncs.com/compatible-mode/v1`
- æ³¨æ„ï¼šbabeldoc ä¼šè‡ªåŠ¨åœ¨ Base URL åæ·»åŠ  /chat/completions

ğŸ“‚ æœ¬åœ°æ¨¡å‹ç”¨æˆ·è¯·ç¡®ä¿ `Ollama` æœåŠ¡å™¨å·²è¿è¡Œï¼Œå¹¶åŠ è½½æ¨¡å‹ï¼ˆå¦‚ llama3ã€gemma ç­‰ï¼‰ã€‚
'''
    )

    with gr.Row():
        pdf_file = gr.File(label="ä¸Šä¼  PDF æ–‡ä»¶", file_types=[".pdf"], type="filepath")

    with gr.Row():
        provider = gr.Radio(
            label="é€‰æ‹©ç¿»è¯‘æ¨¡å‹æ¥æº",
            choices=list(MODEL_PRESETS.keys()),
            value=saved_settings[0]
        )

    with gr.Row():
        api_key = gr.Text(label="API Key", type="password", value=saved_settings[1])
        base_url = gr.Text(label="API Base URL", value=saved_settings[2])
        model_name = gr.Textbox(label="æ¨¡å‹åç§°", value=saved_settings[3], interactive=True)
        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨")

    with gr.Row():
        lang_in = gr.Dropdown(label="æºè¯­è¨€", choices=["en", "zh", "ja"], value=saved_settings[4])
        lang_out = gr.Dropdown(label="ç›®æ ‡è¯­è¨€", choices=["zh", "en", "ja"], value=saved_settings[5])
    
    with gr.Row():
        save_btn = gr.Button("ğŸ’¾ ä¿å­˜å½“å‰è®¾ç½®")
        save_status = gr.Textbox(label="ä¿å­˜çŠ¶æ€", interactive=False, visible=False)

    with gr.Row():
        dual_output = gr.Checkbox(label="è¾“å‡ºåŒè¯­ PDF", value=saved_settings[6])
        no_watermark = gr.Checkbox(label="æ— æ°´å°è¾“å‡º", value=saved_settings[7])
        skip_clean = gr.Checkbox(label="è·³è¿‡ PDF æ¸…æ´— (skip-clean)", value=saved_settings[8])
        rich_text_disable = gr.Checkbox(label="ç¦ç”¨å¯Œæ–‡æœ¬ç¿»è¯‘ (disable-rich-text-translate)", value=saved_settings[9])
        enhance = gr.Checkbox(label="å¢å¼ºå…¼å®¹æ€§ (enhance-compatibility)", value=saved_settings[10])
        max_pages = gr.Textbox(label="æœ€å¤§åˆ†å—é¡µæ•° (max-pages-per-part)", value=saved_settings[11])
        min_length = gr.Textbox(label="æœ€å°ç¿»è¯‘é•¿åº¦ (min-text-length)", value=saved_settings[12])

    run_button = gr.Button("ğŸš€ å¼€å§‹ç¿»è¯‘")
    status = gr.Textbox(label="çŠ¶æ€", interactive=False)
    result_pdf = gr.File(label="ç¿»è¯‘ç»“æœä¸‹è½½")



    provider.change(fn=update_provider, inputs=provider,
                    outputs=[api_key, base_url, model_name])

    refresh_btn.click(fn=refresh_models,
                      inputs=[api_key, base_url],
                      outputs=model_name)

    def save_and_show_status(*args):
        result = save_current_settings(*args)
        return gr.update(visible=True, value=result)
    
    save_btn.click(
        fn=save_and_show_status,
        inputs=[provider, api_key, base_url, model_name, lang_in, lang_out,
                dual_output, no_watermark, skip_clean, rich_text_disable, 
                enhance, max_pages, min_length],
        outputs=save_status
    )



    run_button.click(
        fn=translate_pdf,
        inputs=[pdf_file, provider, api_key, base_url, model_name,
                lang_in, lang_out, dual_output, no_watermark,
                skip_clean, rich_text_disable, enhance, max_pages, min_length],
        outputs=[status, result_pdf]
    )

if __name__ == "__main__":
    demo.launch()
